{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM,Dense,Embedding,Input,Dropout\n",
    "from  keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import os\n",
    "import time\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir('./aclImdb/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "labels = []\n",
    "for i in dirs:\n",
    "    if i == 'neg':\n",
    "        for j in os.listdir('./aclImdb/train/neg'):\n",
    "            with open('./aclImdb/train/neg/'+j, 'rb') as f:\n",
    "                text.append(f.read())\n",
    "                labels.append([1,0])\n",
    "    if i == 'pos':\n",
    "        for j in os.listdir('./aclImdb/train/pos'):\n",
    "            with open('./aclImdb/train/pos/'+j, 'rb') as f:\n",
    "                text.append(f.read())\n",
    "                labels.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_set = set()\n",
    "for x in text:\n",
    "    for i in str(x).split(' '):\n",
    "        my_set.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295309"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for index, word in enumerate(my_set):\n",
    "    word_dict[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    vector = []\n",
    "    for word in text.split(' '):\n",
    "        vector.append(word_dict[word])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector takes fixed lenght i/p so we pad remaining\n",
    "reviews = []\n",
    "for review in text[:1000]:\n",
    "    reviews.append(encode(str(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pad_sequences(reviews,maxlen=100,value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,  27789, 146859,  36222, 245350, 131211,\n",
       "       117847, 124111,  64241, 162775, 122688, 251065, 184495, 204113,\n",
       "        78894, 184495, 213035, 236372,  72582,  74826,  24162, 184495,\n",
       "       266666, 200350,  66696, 281833, 262539, 121202, 131211, 122688,\n",
       "       118827,  63056, 240682, 208631,  99749, 167929, 266666, 159925,\n",
       "       146372, 246181,  92889,  41309], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews, labels = shuffle(reviews, labels[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/khushmeetsingh/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/khushmeetsingh/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           18899840  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 18,932,994\n",
      "Trainable params: 18,932,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "1000/1000 [==============================] - 6s - loss: 0.1716 - acc: 0.9560     \n",
      "Epoch 2/7\n",
      "1000/1000 [==============================] - 6s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 3/7\n",
      "1000/1000 [==============================] - 6s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 4/7\n",
      "1000/1000 [==============================] - 5s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 5/7\n",
      "1000/1000 [==============================] - 5s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 6/7\n",
      "1000/1000 [==============================] - 6s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 7/7\n",
      "1000/1000 [==============================] - 5s - loss: 1.1921e-07 - acc: 1.0000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f77dc50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(my_set)+1,64,input_length=100))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(reviews, np.array(labels[:1000]),batch_size=100,verbose=1,epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
